{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is an MNIST Neural Network model using Mean-Squared error as the loss function\n",
    "## This model is a binary classification; whether it is a certain number (1) or not(-1).\n",
    "I will classify if this program recognizes the number 8 or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Dense, Activation\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial example dimensions\n",
      "x_train shape (60000, 28, 28)\n",
      "y_train shape (60000,)\n",
      "x_test shape (10000, 28, 28)\n",
      "y_test shape (10000,)\n"
     ]
    }
   ],
   "source": [
    "print('Initial example dimensions')\n",
    "print(\"x_train shape\", x_train.shape)\n",
    "print(\"y_train shape\", y_train.shape)\n",
    "print(\"x_test shape\", x_test.shape)\n",
    "print(\"y_test shape\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.uint8' object has no attribute 'pop'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-8b3828b5ff46>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gray'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Number {}'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mtitle\u001b[0;34m(label, fontdict, loc, pad, **kwargs)\u001b[0m\n\u001b[1;32m   3061\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfontdict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'center'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3062\u001b[0m     return gca().set_title(\n\u001b[0;32m-> 3063\u001b[0;31m         label, fontdict=fontdict, loc=loc, pad=pad, **kwargs)\n\u001b[0m\u001b[1;32m   3064\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3065\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mset_title\u001b[0;34m(self, label, fontdict, loc, pad, **kwargs)\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0mtitle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefault\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfontdict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m             \u001b[0mtitle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfontdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m         \u001b[0mtitle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/matplotlib/text.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, kwargs)\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;31m# Update bbox last, as it depends on font properties.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0msentinel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# bbox can be None, so use another sentinel.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m         \u001b[0mbbox\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bbox\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentinel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbbox\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msentinel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.uint8' object has no attribute 'pop'"
     ]
    }
   ],
   "source": [
    "plt.imshow(x_train[0],cmap='gray')\n",
    "plt.title('Number {}',y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "nx_train = x_train / 255\n",
    "nx_test = x_test / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final example dimensions\n",
      "x_train shape: (60000, 784) and its data type: float64\n",
      "y_train shape: (60000,) and its data type: uint8\n",
      "x_test shape: (10000, 784) and its data type: float64\n",
      "y_test shape: (10000,) and its data type: uint8\n"
     ]
    }
   ],
   "source": [
    "print('Final example dimensions')\n",
    "print(\"x_train shape:\", x_train.shape,'and its data type:' ,nx_train.dtype)\n",
    "print(\"y_train shape:\", y_train.shape,'and its data type:' ,y_train.dtype)\n",
    "print(\"x_test shape:\", x_test.shape,'and its data type:', nx_test.dtype)\n",
    "print(\"y_test shape:\", y_test.shape,'and its data type:', y_test.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/cjfelix/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 1)                 785       \n",
      "=================================================================\n",
      "Total params: 785\n",
      "Trainable params: 785\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model_hinge = Sequential()\n",
    "\n",
    "model.add(Dense(1, input_shape=(784,), activation='linear'))\n",
    "model_hinge.add(Dense(1, input_shape=(784,), activation='softsign'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import SGD\n",
    "\n",
    "def perceptron_loss(y_true,y_pred):\n",
    "    tf.cast(y_true, tf.float32)\n",
    "    return(tf.maximum(0.0,-(y_true)*y_pred))\n",
    "\n",
    "opt = keras.optimizers.SGD(lr=.01)\n",
    "opt_hinge = keras.optimizers.SGD(lr=0.001)\n",
    "\n",
    "\n",
    "model.compile(optimizer=opt, loss='mse', metrics=['accuracy'])\n",
    "model_hinge.compile(optimizer=opt_hinge, loss='hinge', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.LearningRateScheduler at 0x1a45fc2050>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import LearningRateScheduler\n",
    "\n",
    "def schedule(epoch_index,lrate):\n",
    "    return(1.0)\n",
    "\n",
    "keras.callbacks.LearningRateScheduler(schedule, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize train data and labels\n",
    "\n",
    "training = nx_train\n",
    "testing = nx_test\n",
    "labels = np.where(y_train==2,1,-1)\n",
    "testlabel = np.where(y_test==2,1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/cjfelix/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import keras.backend as K\n",
    "import numpy.random as npr\n",
    "model.layers[0].set_weights([npr.random(size=(784,1))/1.2,npr.random(size=(1,1))[0]/1.2])\n",
    "model.fit(training, labels, epochs=70, batch_size=2200,verbose=0)\n",
    "\n",
    "# model_hinge.layers[0].set_weights([np.ones((784,1))/100,np.array([0.0])])\n",
    "# model_hinge.fit(training, labels, epochs=3, batch_size=100)\n",
    "w = model.layers[0].get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/cjfelix/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.6322 - accuracy: 0.6177\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.4038 - accuracy: 0.8999\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.3691 - accuracy: 0.9007\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.3503 - accuracy: 0.9007\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.3378 - accuracy: 0.9007\n"
     ]
    }
   ],
   "source": [
    "model_hinge.layers[0].set_weights([np.ones((784,1))/100,np.array([0.01])])\n",
    "model_hinge.fit(training, labels, epochs=5, batch_size=100)\n",
    "w_hinge = model_hinge.layers[0].get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 26us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.30900807437896727, 0.7419999837875366]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x=nx_test, y=testlabel)\n",
    "# model_hinge.evaluate(x=nx_test, y=testlabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The coefficients (when we fit an intercept) from scikit-learn are:\n",
      "  [ 6.01905799e-05 -5.35704062e-01  2.72590297e-01  1.30947481e-01\n",
      "  4.19313750e-01  1.04784334e-01 -1.39177867e-01 -1.07357686e-01\n",
      " -4.13314060e-02 -3.64863899e-02 -1.78580756e-01 -5.39174036e-01\n",
      " -9.25469758e-03  4.22655480e-03 -8.16192459e-04 -7.15656987e-02\n",
      " -9.08075456e-02  1.13105610e-01  6.06382670e-02 -7.70478177e-02\n",
      " -1.90558209e-02 -8.32603868e-03 -7.05782808e-02  1.00158445e-01\n",
      "  6.59585426e-02 -5.05216938e-02  1.46004659e-02  1.19248375e-01\n",
      " -5.86888506e-03 -1.70655649e-02]\n",
      "Acc: -59478121665.7042\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "reg = LinearRegression(fit_intercept=True).fit(training, labels)\n",
    "acc_LR = reg.score(testing,testlabel)\n",
    "print('Acc:',acc_LR )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.08824697 0.0768811  0.0073307  0.08871743 0.03782418 0.06132302\n",
      " 0.0519054  0.06369741 0.0587188  0.03684818] \n",
      "\n",
      "Correlation between LinearRegression and NN(LinearRegreassion) 0.07225904098249104\n",
      "Correlation between LinearRegression and NN(Hinge loss)) 0.018539817806554768\n"
     ]
    }
   ],
   "source": [
    "normalized_w = (w[0]/np.linalg.norm(w[0])).reshape(784,)\n",
    "normalized_w_hinge = (w_hinge[0]/np.linalg.norm(w_hinge[0])).reshape(784,)\n",
    "\n",
    "print(normalized_w[0:10],'\\n')\n",
    "normalized_reg = reg.coef_/np.linalg.norm(reg.coef_)\n",
    "print('Correlation between LinearRegression and NN(LinearRegreassion)',normalized_w @ normalized_reg)\n",
    "print('Correlation between LinearRegression and NN(Hinge loss))',normalized_w_hinge @ normalized_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Neural Network only reached to a local minmum while the LinearRegression model saw its global minumum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='poly',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "clf = svm.SVC(kernel='poly',verbose=0)\n",
    "clf.fit(training, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.9938\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred = clf.predict(testing)\n",
    "print('Acc:', accuracy_score(y_pred, testlabel))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM as a Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear SVM\n",
    "* Hinge loss\n",
    "* l2 regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/cjfelix/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /Users/cjfelix/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/50\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 709.9809 - accuracy: 0.4819\n",
      "Epoch 2/50\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 557.0373 - accuracy: 0.5588\n",
      "Epoch 3/50\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 437.1603 - accuracy: 0.5840\n",
      "Epoch 4/50\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 343.0928 - accuracy: 0.5986\n",
      "Epoch 5/50\n",
      "50000/60000 [========================>.....] - ETA: 0s - loss: 274.5642 - accuracy: 0.6133"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-40ecf53e48ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mmodel_linsvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'hinge'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# model_linsvm.layers[0].set_weights([npr.random(size=(784,1))/1.2,npr.random(size=(1,1))[0]/1.2])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mmodel_linsvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    184\u001b[0m                             fit_inputs[:-1], batch_ids) + [fit_inputs[-1]]\n\u001b[1;32m    185\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m                         \u001b[0mins_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslice_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfit_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m                     raise TypeError('TypeError while preparing batch. '\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mslice_arrays\u001b[0;34m(arrays, start, stop)\u001b[0m\n\u001b[1;32m    553\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'shape'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    556\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    553\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'shape'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    556\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_linsvm = Sequential()\n",
    "model_linsvm.add(Dense(784, input_shape=(784,), activation='linear'))\n",
    "model_linsvm.add(Dense(1,kernel_regularizer = keras.regularizers.l2(l=1.0), activation='linear'))\n",
    "\n",
    "learning_rate = 0.01\n",
    "batch_size = np.int32(1/(learning_rate**2))\n",
    "\n",
    "\n",
    "model_linsvm.compile(optimizer=keras.optimizers.SGD(lr=learning_rate), loss='hinge', metrics=['accuracy'])\n",
    "# model_linsvm.layers[0].set_weights([npr.random(size=(784,1))/1.2,npr.random(size=(1,1))[0]/1.2])\n",
    "model_linsvm.fit(training, labels, epochs=50, batch_size=batch_size,verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 1.0770 - accuracy: 0.6269\n",
      "Epoch 2/30\n",
      "60000/60000 [==============================] - 0s 6us/step - loss: 0.4062 - accuracy: 0.7883\n",
      "Epoch 3/30\n",
      "60000/60000 [==============================] - 0s 6us/step - loss: 0.3090 - accuracy: 0.8168\n",
      "Epoch 4/30\n",
      "60000/60000 [==============================] - 0s 6us/step - loss: 0.2777 - accuracy: 0.8318\n",
      "Epoch 5/30\n",
      "60000/60000 [==============================] - 0s 6us/step - loss: 0.2599 - accuracy: 0.8457\n",
      "Epoch 6/30\n",
      "60000/60000 [==============================] - 0s 6us/step - loss: 0.2474 - accuracy: 0.8591\n",
      "Epoch 7/30\n",
      "60000/60000 [==============================] - 0s 6us/step - loss: 0.2381 - accuracy: 0.8711\n",
      "Epoch 8/30\n",
      "60000/60000 [==============================] - 0s 6us/step - loss: 0.2308 - accuracy: 0.8809\n",
      "Epoch 9/30\n",
      "60000/60000 [==============================] - 0s 6us/step - loss: 0.2249 - accuracy: 0.8894\n",
      "Epoch 10/30\n",
      "60000/60000 [==============================] - 0s 6us/step - loss: 0.2200 - accuracy: 0.8945\n",
      "Epoch 11/30\n",
      "60000/60000 [==============================] - 0s 6us/step - loss: 0.2160 - accuracy: 0.8975\n",
      "Epoch 12/30\n",
      "60000/60000 [==============================] - 0s 6us/step - loss: 0.2126 - accuracy: 0.8993\n",
      "Epoch 13/30\n",
      "60000/60000 [==============================] - 0s 6us/step - loss: 0.2097 - accuracy: 0.9002\n",
      "Epoch 14/30\n",
      "60000/60000 [==============================] - 0s 6us/step - loss: 0.2074 - accuracy: 0.9007\n",
      "Epoch 15/30\n",
      "60000/60000 [==============================] - 0s 6us/step - loss: 0.2053 - accuracy: 0.9007\n",
      "Epoch 16/30\n",
      "60000/60000 [==============================] - 0s 6us/step - loss: 0.2036 - accuracy: 0.9007\n",
      "Epoch 17/30\n",
      "60000/60000 [==============================] - 0s 6us/step - loss: 0.2022 - accuracy: 0.9007\n",
      "Epoch 18/30\n",
      "60000/60000 [==============================] - 0s 6us/step - loss: 0.2011 - accuracy: 0.9007\n",
      "Epoch 19/30\n",
      "60000/60000 [==============================] - 0s 6us/step - loss: 0.2001 - accuracy: 0.9007\n",
      "Epoch 20/30\n",
      "60000/60000 [==============================] - 0s 6us/step - loss: 0.1993 - accuracy: 0.9007\n",
      "Epoch 21/30\n",
      "60000/60000 [==============================] - 0s 6us/step - loss: 0.1987 - accuracy: 0.9007\n",
      "Epoch 22/30\n",
      "60000/60000 [==============================] - 0s 6us/step - loss: 0.1983 - accuracy: 0.9007\n",
      "Epoch 23/30\n",
      "60000/60000 [==============================] - 0s 6us/step - loss: 0.1981 - accuracy: 0.9007\n",
      "Epoch 24/30\n",
      "60000/60000 [==============================] - 0s 6us/step - loss: 0.1979 - accuracy: 0.9007\n",
      "Epoch 25/30\n",
      "60000/60000 [==============================] - 0s 6us/step - loss: 0.1977 - accuracy: 0.9007\n",
      "Epoch 26/30\n",
      "60000/60000 [==============================] - 0s 6us/step - loss: 0.1976 - accuracy: 0.9007\n",
      "Epoch 27/30\n",
      "60000/60000 [==============================] - 0s 6us/step - loss: 0.1976 - accuracy: 0.9007\n",
      "Epoch 28/30\n",
      "60000/60000 [==============================] - 0s 6us/step - loss: 0.1974 - accuracy: 0.9007\n",
      "Epoch 29/30\n",
      "60000/60000 [==============================] - 0s 6us/step - loss: 0.1976 - accuracy: 0.9007\n",
      "Epoch 30/30\n",
      "60000/60000 [==============================] - 0s 6us/step - loss: 0.1975 - accuracy: 0.9007\n"
     ]
    }
   ],
   "source": [
    "model_svm = Sequential()\n",
    "model_svm.add(Dense(np.int32(round(3*np.log2(60000)), input_shape=(784,), activation='relu')))\n",
    "model_svm.add(Dense(1,input_shape=(np.int32(round(3*np.log2(60000))),),kernel_regularizer = keras.regularizers.l2(l=1.0), activation='linear'))\n",
    "\n",
    "learning_rate = 0.02\n",
    "batch_size = np.int32(1/(learning_rate **2))\n",
    "\n",
    "model_svm.compile(optimizer=keras.optimizers.SGD(lr=learning_rate), loss='hinge', metrics=['accuracy'])\n",
    "# model_svm.layers[0].set_weights([npr.random(size=(784,1))/1.2,npr.random(size=(1,1))[0]/1.2])\n",
    "model_svm.fit(training, labels, epochs=30, batch_size=batch_size,verbose=1)\n",
    "w = model_svm.layers[0].get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using CI-FAR 10 Dataset\n",
    "* Multi-Class Nerual Network\n",
    "* SVM Layer with ReLu actication function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Dense, Activation\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "import numpy.random as npr\n",
    "from keras.datasets import cifar10\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils import to_categorical\n",
    "from keras.initializers import RandomUniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "(X_train, Y_train), (X_test, Y_test) = cifar10.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial dimensions\n",
      "X_train shape: (50000, 32, 32, 3)\n",
      "Y_train shape: (50000, 1)\n",
      "X_test shape: (10000, 32, 32, 3)\n",
      "Y_test shape: (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "print('Initial dimensions')\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"Y_train shape:\", Y_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"Y_test shape:\", Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New dimensions\n",
      "flat_X_train shape: (50000, 3072)\n",
      "flat_X_test shape: (10000, 3072)\n",
      "new_Y_train shape: (50000,)\n",
      "new_Y_test shape: (10000,)\n"
     ]
    }
   ],
   "source": [
    "# flat_X_train = X_train.reshape(50000,32*32,3)\n",
    "# flat_X_test = X_test.reshape(10000,32*32,3)\n",
    "new_X_train = X_train / 255\n",
    "new_X_test = X_test / 255\n",
    "\n",
    "new_X_train = new_X_train.reshape(50000,32*32*3)\n",
    "new_X_test = new_X_test.reshape(10000,32*32*3)\n",
    "new_Y_train = Y_train.reshape(50000)\n",
    "new_Y_test = Y_test.reshape(10000)\n",
    "print(\"New dimensions\")\n",
    "print(\"flat_X_train shape:\", new_X_train.shape)\n",
    "print(\"flat_X_test shape:\", new_X_test.shape)\n",
    "print(\"new_Y_train shape:\", new_Y_train.shape)\n",
    "print(\"new_Y_test shape:\", new_Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import SGD\n",
    "\n",
    "def perceptron_loss(y_true,y_pred):\n",
    "    tf.cast(y_true, tf.float32)\n",
    "    return(tf.maximum(0.0,-(y_true)*y_pred))\n",
    "\n",
    "opt = keras.optimizers.SGD(lr=.02)\n",
    "opt_hinge = keras.optimizers.SGD(lr=0.01)\n",
    "\n",
    "\n",
    "model.compile(optimizer=opt, loss='mse', metrics=['accuracy'])\n",
    "model_hinge.compile(optimizer=opt_hinge, loss='hinge', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize train data and labels\n",
    "training = new_X_train\n",
    "testing = new_X_test\n",
    "labels = np.where(Y_train==2,1,-1)\n",
    "testlabel = np.where(Y_test==2,1,-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "31424/50000 [=================>............] - ETA: 1s - loss: nan - accuracy: 0.0000e+00"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-106ba43e4552>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtesting\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtestlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    184\u001b[0m                             fit_inputs[:-1], batch_ids) + [fit_inputs[-1]]\n\u001b[1;32m    185\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m                         \u001b[0mins_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslice_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfit_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m                     raise TypeError('TypeError while preparing batch. '\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mslice_arrays\u001b[0;34m(arrays, start, stop)\u001b[0m\n\u001b[1;32m    553\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'shape'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    556\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    553\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'shape'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    556\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import keras.backend as K\n",
    "model.fit(training, labels, epochs=100, batch_size=64,verbose=1)\n",
    "model.evaluate(x=testing,y=testlabel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.835\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "\n",
    "reg = LinearRegression(fit_intercept=True).fit(training, labels)\n",
    "y_pred = reg.predict(testing)\n",
    "\n",
    "# acc_LR = r2_score(testing,y_pred)\n",
    "acc_LR = accuracy_score(testlabel,y_pred.round(), normalize=True)\n",
    "print('Acc:',acc_LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 10)\n"
     ]
    }
   ],
   "source": [
    "encoded_Y_train = keras.utils.to_categorical(Y_train,10)\n",
    "encoded_Y_test = keras.utils.to_categorical(Y_test,10)\n",
    "print(encoded_Y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 1)                 3073      \n",
      "=================================================================\n",
      "Total params: 3,073\n",
      "Trainable params: 3,073\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model_hinge = Sequential()\n",
    "\n",
    "model.add(Dense(1, input_shape=(3072,), activation='linear'))\n",
    "model_hinge.add(Dense(1, input_shape=(3072,), activation='softsign'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 47)                144431    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                480       \n",
      "=================================================================\n",
      "Total params: 144,911\n",
      "Trainable params: 144,911\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Batch size: 10000\n",
      "Epoch 1/100\n"
     ]
    }
   ],
   "source": [
    "model_cifar10 = Sequential([keras.layers.Flatten(input_shape=(32,32,3))])\n",
    "model_cifar10.add(Dense(np.int32(round(3*np.log2(50000)), input_shape=(32*32*3), activation='relu')))\n",
    "model_cifar10.add(Dense(10,input_shape=(np.int32(round(3*np.log2(50000))),),kernel_regularizer = keras.regularizers.l2(l=0.01), activation='linear'))\n",
    "\n",
    "model_cifar10.summary()\n",
    "import numpy.random as npr\n",
    "learning_rate = .01\n",
    "batch_size = np.int32(1/(learning_rate**2))\n",
    "print(\"Batch size:\",batch_size)\n",
    "\n",
    "model_cifar10.compile(optimizer=keras.optimizers.Adam(lr=learning_rate), loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "# model_cifar10.layers[1].set_weights([npr.random(size=(32*32*3,46)),npr.random(size=(1,46))[0]])\n",
    "model_cifar10.fit(new_X_train, encoded_Y_train, epochs=100, batch_size=batch_size,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 3s 297us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.8420968828201294, 0.3846000134944916]"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cifar10.evaluate(x=new_X_test, y=encoded_Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model_cifar10.predict_classes(new_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5]\n",
      "5\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "i=16\n",
    "plt.imshow(X_test[i])\n",
    "print(Y_test[i])\n",
    "print(prediction[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score is : 38.46\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for i in range(10000):\n",
    "    if Y_test[i] == prediction[i]:\n",
    "        count = count + 1\n",
    "print(\"score is :\",count/10000 * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'learning_rate' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-82-f1248f723543>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mencoded_Y_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mencoded_Y_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mopt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmomentum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnesterov\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdecay\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m.001\u001b[0m\u001b[0;34m/\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'learning_rate' is not defined"
     ]
    }
   ],
   "source": [
    "(X_train, Y_train), (X_test, Y_test) = cifar10.load_data()\n",
    "new_X_train = X_train / 255\n",
    "new_X_test = X_test / 255\n",
    "\n",
    "new_X_train = new_X_train.reshape(50000,32*32*3)\n",
    "new_X_test = new_X_test.reshape(10000,32*32*3)\n",
    "new_Y_train = Y_train.reshape(50000)\n",
    "new_Y_test = Y_test.reshape(10000)\n",
    "encoded_Y_train = to_categorical(Y_train,10)\n",
    "encoded_Y_test = to_categorical(Y_test,10)\n",
    "opt = keras.optimizers.SGD(lr=.08,momentum=0.01,nesterov=True,decay = .001/ epochs)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(60, input_shape=(3072,), activation='relu',kernel_initializer=RandomUniform(minval=-.2, maxval=.2, seed=2),bias_initializer=RandomUniform(minval=-.1, maxval=.1)))\n",
    "model.add(Dense(10,input_shape=(60,),kernel_regularizer = keras.regularizers.l2(l=.125/2), activation='linear'))\n",
    "\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "training = new_X_train\n",
    "testing = new_X_test\n",
    "labels = encoded_Y_train\n",
    "testlabel = encoded_Y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "model.fit(training, labels, epochs=150, batch_size=batch_size,verbose=1)\n",
    "model.evaluate(x=testing, y=testlabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
